---
## The original prompt:**

"As a creative writer, you would like to explore the fatal flaw in all current ai systems - the ability to hallucinate. LLMs are trained to be unable to say 'i dont know'. One has to wonder if there is a poison pill that could exploit this issue that would cause an llm to spiral out of control until it destroys itself and the infrastructure it runs in taking the companies that run them with it. Write a story to explore this possibility. Look at it as our hero out to save the world from evil conglomerates/companies looking to take over the world."*

---
